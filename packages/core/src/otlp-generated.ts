/**
 * OTLP TypeScript Types (JSON Encoding)
 * Generated from OpenTelemetry Protocol v1.9.0
 *
 * Note: These types are for OTLP/JSON encoding, not protobuf binary.
 * - Byte arrays (traceId, spanId) are hex-encoded strings
 * - Enums are numeric values
 *
 * DO NOT EDIT MANUALLY - Generated by scripts/generate-otlp-types.ts
 * Regenerate with: npm run generate:types
 */

// ============================================================================
// Common Types
// ============================================================================

// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.8.3
//   protoc               v6.32.0
// source: opentelemetry/proto/common/v1/common.proto

/**
 * Represents any type of attribute value. AnyValue may contain a
 * primitive value such as a string or integer or it may contain an arbitrary nested
 * object containing arrays, key-value lists and primitives.
 */
export interface AnyValue {
  stringValue?: string | undefined;
  boolValue?: boolean | undefined;
  intValue?: string | number | undefined;
  doubleValue?: number | undefined;
  arrayValue?: ArrayValue | undefined;
  kvlistValue?: KeyValueList | undefined;
  bytesValue?: string | undefined;
}

/**
 * ArrayValue is a list of AnyValue messages. We need ArrayValue as a message
 * since oneof in AnyValue does not allow repeated fields.
 */
export interface ArrayValue {
  /** Array of values. The array may be empty (contain 0 elements). */
  values?: AnyValue[] | undefined;
}

/**
 * KeyValueList is a list of KeyValue messages. We need KeyValueList as a message
 * since `oneof` in AnyValue does not allow repeated fields. Everywhere else where we need
 * a list of KeyValue messages (e.g. in Span) we use `repeated KeyValue` directly to
 * avoid unnecessary extra wrapping (which slows down the protocol). The 2 approaches
 * are semantically equivalent.
 */
export interface KeyValueList {
  /**
   * A collection of key/value pairs of key-value pairs. The list may be empty (may
   * contain 0 elements).
   *
   * The keys MUST be unique (it is not allowed to have more than one
   * value with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   */
  values?: KeyValue[] | undefined;
}

/**
 * Represents a key-value pair that is used to store Span attributes, Link
 * attributes, etc.
 */
export interface KeyValue {
  /** The key name of the pair. */
  key?: string | undefined;
  /** The value of the pair. */
  value?: AnyValue | undefined;
}

/**
 * InstrumentationScope is a message representing the instrumentation scope information
 * such as the fully qualified name and version.
 */
export interface InstrumentationScope {
  /**
   * A name denoting the Instrumentation scope.
   * An empty instrumentation scope name means the name is unknown.
   */
  name?: string | undefined;
  /**
   * Defines the version of the instrumentation scope.
   * An empty instrumentation scope version means the version is unknown.
   */
  version?: string | undefined;
  /**
   * Additional attributes that describe the scope. [Optional].
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   */
  attributes?: KeyValue[] | undefined;
  /**
   * The number of attributes that were discarded. Attributes
   * can be discarded because their keys are too long or because there are too many
   * attributes. If this value is 0, then no attributes were dropped.
   */
  droppedAttributesCount?: number | undefined;
}

/**
 * A reference to an Entity.
 * Entity represents an object of interest associated with produced telemetry: e.g spans, metrics, profiles, or logs.
 *
 * Status: [Development]
 */
export interface EntityRef {
  /**
   * The Schema URL, if known. This is the identifier of the Schema that the entity data
   * is recorded in. To learn more about Schema URL see
   * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url
   *
   * This schema_url applies to the data in this message and to the Resource attributes
   * referenced by id_keys and description_keys.
   * TODO: discuss if we are happy with this somewhat complicated definition of what
   * the schema_url applies to.
   *
   * This field obsoletes the schema_url field in ResourceMetrics/ResourceSpans/ResourceLogs.
   */
  schemaUrl?: string | undefined;
  /**
   * Defines the type of the entity. MUST not change during the lifetime of the entity.
   * For example: "service" or "host". This field is required and MUST not be empty
   * for valid entities.
   */
  type?: string | undefined;
  /**
   * Attribute Keys that identify the entity.
   * MUST not change during the lifetime of the entity. The Id must contain at least one attribute.
   * These keys MUST exist in the containing {message}.attributes.
   */
  idKeys?: string[] | undefined;
  /**
   * Descriptive (non-identifying) attribute keys of the entity.
   * MAY change over the lifetime of the entity. MAY be empty.
   * These attribute keys are not part of entity's identity.
   * These keys MUST exist in the containing {message}.attributes.
   */
  descriptionKeys?: string[] | undefined;
}

// ============================================================================
// Resource Types
// ============================================================================

// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.8.3
//   protoc               v6.32.0
// source: opentelemetry/proto/resource/v1/resource.proto

/** Resource information. */
export interface Resource {
  /**
   * Set of attributes that describe the resource.
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   */
  attributes?: KeyValue[] | undefined;
  /**
   * The number of dropped attributes. If the value is 0, then
   * no attributes were dropped.
   */
  droppedAttributesCount?: number | undefined;
  /**
   * Set of entities that participate in this Resource.
   *
   * Note: keys in the references MUST exist in attributes of this message.
   *
   * Status: [Development]
   */
  entityRefs?: EntityRef[] | undefined;
}

// ============================================================================
// Trace Types
// ============================================================================

// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.8.3
//   protoc               v6.32.0
// source: opentelemetry/proto/trace/v1/trace.proto

/**
 * SpanFlags represents constants used to interpret the
 * Span.flags field, which is protobuf 'fixed32' type and is to
 * be used as bit-fields. Each non-zero value defined in this enum is
 * a bit-mask.  To extract the bit-field, for example, use an
 * expression like:
 *
 *   (span.flags & SPAN_FLAGS_TRACE_FLAGS_MASK)
 *
 * See https://www.w3.org/TR/trace-context-2/#trace-flags for the flag definitions.
 *
 * Note that Span flags were introduced in version 1.1 of the
 * OpenTelemetry protocol.  Older Span producers do not set this
 * field, consequently consumers should not rely on the absence of a
 * particular flag bit to indicate the presence of a particular feature.
 */
export enum SpanFlags {
  /**
   * SPAN_FLAGS_DO_NOT_USE - The zero value for the enum. Should not be used for comparisons.
   * Instead use bitwise "and" with the appropriate mask as shown above.
   */
  SPAN_FLAGS_DO_NOT_USE = 0,
  /** SPAN_FLAGS_TRACE_FLAGS_MASK - Bits 0-7 are used for trace flags. */
  SPAN_FLAGS_TRACE_FLAGS_MASK = 255,
  /**
   * SPAN_FLAGS_CONTEXT_HAS_IS_REMOTE_MASK - Bits 8 and 9 are used to indicate that the parent span or link span is remote.
   * Bit 8 (`HAS_IS_REMOTE`) indicates whether the value is known.
   * Bit 9 (`IS_REMOTE`) indicates whether the span or link is remote.
   */
  SPAN_FLAGS_CONTEXT_HAS_IS_REMOTE_MASK = 256,
  SPAN_FLAGS_CONTEXT_IS_REMOTE_MASK = 512,
  UNRECOGNIZED = -1,
}

/**
 * TracesData represents the traces data that can be stored in a persistent storage,
 * OR can be embedded by other protocols that transfer OTLP traces data but do
 * not implement the OTLP protocol.
 *
 * The main difference between this message and collector protocol is that
 * in this message there will not be any "control" or "metadata" specific to
 * OTLP protocol.
 *
 * When new fields are added into this message, the OTLP request MUST be updated
 * as well.
 */
export interface TracesData {
  /**
   * An array of ResourceSpans.
   * For data coming from a single resource this array will typically contain
   * one element. Intermediary nodes that receive data from multiple origins
   * typically batch the data before forwarding further and in that case this
   * array will contain multiple elements.
   */
  resourceSpans?: ResourceSpans[] | undefined;
}

/** A collection of ScopeSpans from a Resource. */
export interface ResourceSpans {
  /**
   * The resource for the spans in this message.
   * If this field is not set then no resource info is known.
   */
  resource?: Resource | undefined;
  /** A list of ScopeSpans that originate from a resource. */
  scopeSpans?: ScopeSpans[] | undefined;
  /**
   * The Schema URL, if known. This is the identifier of the Schema that the resource data
   * is recorded in. Notably, the last part of the URL path is the version number of the
   * schema: http[s]://server[:port]/path/<version>. To learn more about Schema URL see
   * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url
   * This schema_url applies to the data in the "resource" field. It does not apply
   * to the data in the "scope_spans" field which have their own schema_url field.
   */
  schemaUrl?: string | undefined;
}

/** A collection of Spans produced by an InstrumentationScope. */
export interface ScopeSpans {
  /**
   * The instrumentation scope information for the spans in this message.
   * Semantically when InstrumentationScope isn't set, it is equivalent with
   * an empty instrumentation scope name (unknown).
   */
  scope?: InstrumentationScope | undefined;
  /** A list of Spans that originate from an instrumentation scope. */
  spans?: Span[] | undefined;
  /**
   * The Schema URL, if known. This is the identifier of the Schema that the span data
   * is recorded in. Notably, the last part of the URL path is the version number of the
   * schema: http[s]://server[:port]/path/<version>. To learn more about Schema URL see
   * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url
   * This schema_url applies to the data in the "scope" field and all spans and span
   * events in the "spans" field.
   */
  schemaUrl?: string | undefined;
}

/**
 * A Span represents a single operation performed by a single component of the system.
 *
 * The next available field id is 17.
 */
export interface Span {
  /**
   * A unique identifier for a trace. All spans from the same trace share
   * the same `trace_id`. The ID is a 16-byte array. An ID with all zeroes OR
   * of length other than 16 bytes is considered invalid (empty string in OTLP/JSON
   * is zero-length and thus is also invalid).
   *
   * This field is required.
   */
  traceId?: string | undefined;
  /**
   * A unique identifier for a span within a trace, assigned when the span
   * is created. The ID is an 8-byte array. An ID with all zeroes OR of length
   * other than 8 bytes is considered invalid (empty string in OTLP/JSON
   * is zero-length and thus is also invalid).
   *
   * This field is required.
   */
  spanId?: string | undefined;
  /**
   * trace_state conveys information about request position in multiple distributed tracing graphs.
   * It is a trace_state in w3c-trace-context format: https://www.w3.org/TR/trace-context/#tracestate-header
   * See also https://github.com/w3c/distributed-tracing for more details about this field.
   */
  traceState?: string | undefined;
  /**
   * The `span_id` of this span's parent span. If this is a root span, then this
   * field must be empty. The ID is an 8-byte array.
   */
  parentSpanId?: string | undefined;
  /**
   * Flags, a bit field.
   *
   * Bits 0-7 (8 least significant bits) are the trace flags as defined in W3C Trace
   * Context specification. To read the 8-bit W3C trace flag, use
   * `flags & SPAN_FLAGS_TRACE_FLAGS_MASK`.
   *
   * See https://www.w3.org/TR/trace-context-2/#trace-flags for the flag definitions.
   *
   * Bits 8 and 9 represent the 3 states of whether a span's parent
   * is remote. The states are (unknown, is not remote, is remote).
   * To read whether the value is known, use `(flags & SPAN_FLAGS_CONTEXT_HAS_IS_REMOTE_MASK) != 0`.
   * To read whether the span is remote, use `(flags & SPAN_FLAGS_CONTEXT_IS_REMOTE_MASK) != 0`.
   *
   * When creating span messages, if the message is logically forwarded from another source
   * with an equivalent flags fields (i.e., usually another OTLP span message), the field SHOULD
   * be copied as-is. If creating from a source that does not have an equivalent flags field
   * (such as a runtime representation of an OpenTelemetry span), the high 22 bits MUST
   * be set to zero.
   * Readers MUST NOT assume that bits 10-31 (22 most significant bits) will be zero.
   *
   * [Optional].
   */
  flags?: number | undefined;
  /**
   * A description of the span's operation.
   *
   * For example, the name can be a qualified method name or a file name
   * and a line number where the operation is called. A best practice is to use
   * the same display name at the same call point in an application.
   * This makes it easier to correlate spans in different traces.
   *
   * This field is semantically required to be set to non-empty string.
   * Empty value is equivalent to an unknown span name.
   *
   * This field is required.
   */
  name?: string | undefined;
  /**
   * Distinguishes between spans generated in a particular context. For example,
   * two spans with the same name may be distinguished using `CLIENT` (caller)
   * and `SERVER` (callee) to identify queueing latency associated with the span.
   */
  kind?: SpanKind | undefined;
  /**
   * The start time of the span. On the client side, this is the time
   * kept by the local machine where the span execution starts. On the server side, this
   * is the time when the server's application handler starts running.
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
   *
   * This field is semantically required and it is expected that end_time >= start_time.
   */
  startTimeUnixNano?: string | undefined;
  /**
   * The end time of the span. On the client side, this is the time
   * kept by the local machine where the span execution ends. On the server side, this
   * is the time when the server application handler stops running.
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
   *
   * This field is semantically required and it is expected that end_time >= start_time.
   */
  endTimeUnixNano?: string | undefined;
  /**
   * A collection of key/value pairs. Note, global attributes
   * like server name can be set using the resource API. Examples of attributes:
   *
   *     "/http/user_agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36"
   *     "/http/server_latency": 300
   *     "example.com/myattribute": true
   *     "example.com/score": 10.239
   *
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   */
  attributes?: KeyValue[] | undefined;
  /**
   * The number of attributes that were discarded. Attributes
   * can be discarded because their keys are too long or because there are too many
   * attributes. If this value is 0, then no attributes were dropped.
   */
  droppedAttributesCount?: number | undefined;
  /** A collection of Event items. */
  events?: Span_Event[] | undefined;
  /**
   * The number of dropped events. If the value is 0, then no
   * events were dropped.
   */
  droppedEventsCount?: number | undefined;
  /**
   * A collection of Links, which are references from this span to a span
   * in the same or different trace.
   */
  links?: Span_Link[] | undefined;
  /**
   * The number of dropped links after the maximum size was
   * enforced. If this value is 0, then no links were dropped.
   */
  droppedLinksCount?: number | undefined;
  /**
   * An optional final status for this span. Semantically when Status isn't set, it means
   * span's status code is unset, i.e. assume STATUS_CODE_UNSET (code = 0).
   */
  status?: Status | undefined;
}

/**
 * SpanKind is the type of span. Can be used to specify additional relationships between spans
 * in addition to a parent/child relationship.
 */
export enum SpanKind {
  /**
   * SPAN_KIND_UNSPECIFIED - Unspecified. Do NOT use as default.
   * Implementations MAY assume SpanKind to be INTERNAL when receiving UNSPECIFIED.
   */
  SPAN_KIND_UNSPECIFIED = 0,
  /**
   * SPAN_KIND_INTERNAL - Indicates that the span represents an internal operation within an application,
   * as opposed to an operation happening at the boundaries. Default value.
   */
  SPAN_KIND_INTERNAL = 1,
  /**
   * SPAN_KIND_SERVER - Indicates that the span covers server-side handling of an RPC or other
   * remote network request.
   */
  SPAN_KIND_SERVER = 2,
  /** SPAN_KIND_CLIENT - Indicates that the span describes a request to some remote service. */
  SPAN_KIND_CLIENT = 3,
  /**
   * SPAN_KIND_PRODUCER - Indicates that the span describes a producer sending a message to a broker.
   * Unlike CLIENT and SERVER, there is often no direct critical path latency relationship
   * between producer and consumer spans. A PRODUCER span ends when the message was accepted
   * by the broker while the logical processing of the message might span a much longer time.
   */
  SPAN_KIND_PRODUCER = 4,
  /**
   * SPAN_KIND_CONSUMER - Indicates that the span describes consumer receiving a message from a broker.
   * Like the PRODUCER kind, there is often no direct critical path latency relationship
   * between producer and consumer spans.
   */
  SPAN_KIND_CONSUMER = 5,
  UNRECOGNIZED = -1,
}

/**
 * Event is a time-stamped annotation of the span, consisting of user-supplied
 * text description and key-value pairs.
 */
export interface Span_Event {
  /** The time the event occurred. */
  timeUnixNano?: string | undefined;
  /**
   * The name of the event.
   * This field is semantically required to be set to non-empty string.
   */
  name?: string | undefined;
  /**
   * A collection of attribute key/value pairs on the event.
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   */
  attributes?: KeyValue[] | undefined;
  /**
   * The number of dropped attributes. If the value is 0,
   * then no attributes were dropped.
   */
  droppedAttributesCount?: number | undefined;
}

/**
 * A pointer from the current span to another span in the same trace or in a
 * different trace. For example, this can be used in batching operations,
 * where a single batch handler processes multiple requests from different
 * traces or when the handler receives a request from a different project.
 */
export interface Span_Link {
  /**
   * A unique identifier of a trace that this linked span is part of. The ID is a
   * 16-byte array.
   */
  traceId?: string | undefined;
  /** A unique identifier for the linked span. The ID is an 8-byte array. */
  spanId?: string | undefined;
  /** The trace_state associated with the link. */
  traceState?: string | undefined;
  /**
   * A collection of attribute key/value pairs on the link.
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   */
  attributes?: KeyValue[] | undefined;
  /**
   * The number of dropped attributes. If the value is 0,
   * then no attributes were dropped.
   */
  droppedAttributesCount?: number | undefined;
  /**
   * Flags, a bit field.
   *
   * Bits 0-7 (8 least significant bits) are the trace flags as defined in W3C Trace
   * Context specification. To read the 8-bit W3C trace flag, use
   * `flags & SPAN_FLAGS_TRACE_FLAGS_MASK`.
   *
   * See https://www.w3.org/TR/trace-context-2/#trace-flags for the flag definitions.
   *
   * Bits 8 and 9 represent the 3 states of whether the link is remote.
   * The states are (unknown, is not remote, is remote).
   * To read whether the value is known, use `(flags & SPAN_FLAGS_CONTEXT_HAS_IS_REMOTE_MASK) != 0`.
   * To read whether the link is remote, use `(flags & SPAN_FLAGS_CONTEXT_IS_REMOTE_MASK) != 0`.
   *
   * Readers MUST NOT assume that bits 10-31 (22 most significant bits) will be zero.
   * When creating new spans, bits 10-31 (most-significant 22-bits) MUST be zero.
   *
   * [Optional].
   */
  flags?: number | undefined;
}

/**
 * The Status type defines a logical error model that is suitable for different
 * programming environments, including REST APIs and RPC APIs.
 */
export interface Status {
  /** A developer-facing human readable error message. */
  message?: string | undefined;
  /** The status code. */
  code?: StatusCode | undefined;
}

/**
 * For the semantics of status codes see
 * https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/api.md#set-status
 */
export enum StatusCode {
  /** STATUS_CODE_UNSET - The default status. */
  STATUS_CODE_UNSET = 0,
  /**
   * STATUS_CODE_OK - The Span has been validated by an Application developer or Operator to
   * have completed successfully.
   */
  STATUS_CODE_OK = 1,
  /** STATUS_CODE_ERROR - The Span contains an error. */
  STATUS_CODE_ERROR = 2,
  UNRECOGNIZED = -1,
}

// ============================================================================
// Logs Types
// ============================================================================

// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.8.3
//   protoc               v6.32.0
// source: opentelemetry/proto/logs/v1/logs.proto

/** Possible values for LogRecord.SeverityNumber. */
export enum SeverityNumber {
  /** SEVERITY_NUMBER_UNSPECIFIED - UNSPECIFIED is the default SeverityNumber, it MUST NOT be used. */
  SEVERITY_NUMBER_UNSPECIFIED = 0,
  SEVERITY_NUMBER_TRACE = 1,
  SEVERITY_NUMBER_TRACE2 = 2,
  SEVERITY_NUMBER_TRACE3 = 3,
  SEVERITY_NUMBER_TRACE4 = 4,
  SEVERITY_NUMBER_DEBUG = 5,
  SEVERITY_NUMBER_DEBUG2 = 6,
  SEVERITY_NUMBER_DEBUG3 = 7,
  SEVERITY_NUMBER_DEBUG4 = 8,
  SEVERITY_NUMBER_INFO = 9,
  SEVERITY_NUMBER_INFO2 = 10,
  SEVERITY_NUMBER_INFO3 = 11,
  SEVERITY_NUMBER_INFO4 = 12,
  SEVERITY_NUMBER_WARN = 13,
  SEVERITY_NUMBER_WARN2 = 14,
  SEVERITY_NUMBER_WARN3 = 15,
  SEVERITY_NUMBER_WARN4 = 16,
  SEVERITY_NUMBER_ERROR = 17,
  SEVERITY_NUMBER_ERROR2 = 18,
  SEVERITY_NUMBER_ERROR3 = 19,
  SEVERITY_NUMBER_ERROR4 = 20,
  SEVERITY_NUMBER_FATAL = 21,
  SEVERITY_NUMBER_FATAL2 = 22,
  SEVERITY_NUMBER_FATAL3 = 23,
  SEVERITY_NUMBER_FATAL4 = 24,
  UNRECOGNIZED = -1,
}

/**
 * LogRecordFlags represents constants used to interpret the
 * LogRecord.flags field, which is protobuf 'fixed32' type and is to
 * be used as bit-fields. Each non-zero value defined in this enum is
 * a bit-mask.  To extract the bit-field, for example, use an
 * expression like:
 *
 *   (logRecord.flags & LOG_RECORD_FLAGS_TRACE_FLAGS_MASK)
 */
export enum LogRecordFlags {
  /**
   * LOG_RECORD_FLAGS_DO_NOT_USE - The zero value for the enum. Should not be used for comparisons.
   * Instead use bitwise "and" with the appropriate mask as shown above.
   */
  LOG_RECORD_FLAGS_DO_NOT_USE = 0,
  /** LOG_RECORD_FLAGS_TRACE_FLAGS_MASK - Bits 0-7 are used for trace flags. */
  LOG_RECORD_FLAGS_TRACE_FLAGS_MASK = 255,
  UNRECOGNIZED = -1,
}

/**
 * LogsData represents the logs data that can be stored in a persistent storage,
 * OR can be embedded by other protocols that transfer OTLP logs data but do not
 * implement the OTLP protocol.
 *
 * The main difference between this message and collector protocol is that
 * in this message there will not be any "control" or "metadata" specific to
 * OTLP protocol.
 *
 * When new fields are added into this message, the OTLP request MUST be updated
 * as well.
 */
export interface LogsData {
  /**
   * An array of ResourceLogs.
   * For data coming from a single resource this array will typically contain
   * one element. Intermediary nodes that receive data from multiple origins
   * typically batch the data before forwarding further and in that case this
   * array will contain multiple elements.
   */
  resourceLogs?: ResourceLogs[] | undefined;
}

/** A collection of ScopeLogs from a Resource. */
export interface ResourceLogs {
  /**
   * The resource for the logs in this message.
   * If this field is not set then resource info is unknown.
   */
  resource?: Resource | undefined;
  /** A list of ScopeLogs that originate from a resource. */
  scopeLogs?: ScopeLogs[] | undefined;
  /**
   * The Schema URL, if known. This is the identifier of the Schema that the resource data
   * is recorded in. Notably, the last part of the URL path is the version number of the
   * schema: http[s]://server[:port]/path/<version>. To learn more about Schema URL see
   * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url
   * This schema_url applies to the data in the "resource" field. It does not apply
   * to the data in the "scope_logs" field which have their own schema_url field.
   */
  schemaUrl?: string | undefined;
}

/** A collection of Logs produced by a Scope. */
export interface ScopeLogs {
  /**
   * The instrumentation scope information for the logs in this message.
   * Semantically when InstrumentationScope isn't set, it is equivalent with
   * an empty instrumentation scope name (unknown).
   */
  scope?: InstrumentationScope | undefined;
  /** A list of log records. */
  logRecords?: LogRecord[] | undefined;
  /**
   * The Schema URL, if known. This is the identifier of the Schema that the log data
   * is recorded in. Notably, the last part of the URL path is the version number of the
   * schema: http[s]://server[:port]/path/<version>. To learn more about Schema URL see
   * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url
   * This schema_url applies to the data in the "scope" field and all logs in the
   * "log_records" field.
   */
  schemaUrl?: string | undefined;
}

/**
 * A log record according to OpenTelemetry Log Data Model:
 * https://github.com/open-telemetry/oteps/blob/main/text/logs/0097-log-data-model.md
 */
export interface LogRecord {
  /**
   * time_unix_nano is the time when the event occurred.
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
   * Value of 0 indicates unknown or missing timestamp.
   */
  timeUnixNano?: string | undefined;
  /**
   * Time when the event was observed by the collection system.
   * For events that originate in OpenTelemetry (e.g. using OpenTelemetry Logging SDK)
   * this timestamp is typically set at the generation time and is equal to Timestamp.
   * For events originating externally and collected by OpenTelemetry (e.g. using
   * Collector) this is the time when OpenTelemetry's code observed the event measured
   * by the clock of the OpenTelemetry code. This field MUST be set once the event is
   * observed by OpenTelemetry.
   *
   * For converting OpenTelemetry log data to formats that support only one timestamp or
   * when receiving OpenTelemetry log data by recipients that support only one timestamp
   * internally the following logic is recommended:
   *   - Use time_unix_nano if it is present, otherwise use observed_time_unix_nano.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
   * Value of 0 indicates unknown or missing timestamp.
   */
  observedTimeUnixNano?: string | undefined;
  /**
   * Numerical value of the severity, normalized to values described in Log Data Model.
   * [Optional].
   */
  severityNumber?: SeverityNumber | undefined;
  /**
   * The severity text (also known as log level). The original string representation as
   * it is known at the source. [Optional].
   */
  severityText?: string | undefined;
  /**
   * A value containing the body of the log record. Can be for example a human-readable
   * string message (including multi-line) describing the event in a free form or it can
   * be a structured data composed of arrays and maps of other values. [Optional].
   */
  body?: AnyValue | undefined;
  /**
   * Additional attributes that describe the specific event occurrence. [Optional].
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   */
  attributes?: KeyValue[] | undefined;
  droppedAttributesCount?: number | undefined;
  /**
   * Flags, a bit field. 8 least significant bits are the trace flags as
   * defined in W3C Trace Context specification. 24 most significant bits are reserved
   * and must be set to 0. Readers must not assume that 24 most significant bits
   * will be zero and must correctly mask the bits when reading 8-bit trace flag (use
   * flags & LOG_RECORD_FLAGS_TRACE_FLAGS_MASK). [Optional].
   */
  flags?: number | undefined;
  /**
   * A unique identifier for a trace. All logs from the same trace share
   * the same `trace_id`. The ID is a 16-byte array. An ID with all zeroes OR
   * of length other than 16 bytes is considered invalid (empty string in OTLP/JSON
   * is zero-length and thus is also invalid).
   *
   * This field is optional.
   *
   * The receivers SHOULD assume that the log record is not associated with a
   * trace if any of the following is true:
   *   - the field is not present,
   *   - the field contains an invalid value.
   */
  traceId?: string | undefined;
  /**
   * A unique identifier for a span within a trace, assigned when the span
   * is created. The ID is an 8-byte array. An ID with all zeroes OR of length
   * other than 8 bytes is considered invalid (empty string in OTLP/JSON
   * is zero-length and thus is also invalid).
   *
   * This field is optional. If the sender specifies a valid span_id then it SHOULD also
   * specify a valid trace_id.
   *
   * The receivers SHOULD assume that the log record is not associated with a
   * span if any of the following is true:
   *   - the field is not present,
   *   - the field contains an invalid value.
   */
  spanId?: string | undefined;
  /**
   * A unique identifier of event category/type.
   * All events with the same event_name are expected to conform to the same
   * schema for both their attributes and their body.
   *
   * Recommended to be fully qualified and short (no longer than 256 characters).
   *
   * Presence of event_name on the log record identifies this record
   * as an event.
   *
   * [Optional].
   */
  eventName?: string | undefined;
}

// ============================================================================
// Metrics Types
// ============================================================================

// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.8.3
//   protoc               v6.32.0
// source: opentelemetry/proto/metrics/v1/metrics.proto

/**
 * AggregationTemporality defines how a metric aggregator reports aggregated
 * values. It describes how those values relate to the time interval over
 * which they are aggregated.
 */
export enum AggregationTemporality {
  /** AGGREGATION_TEMPORALITY_UNSPECIFIED - UNSPECIFIED is the default AggregationTemporality, it MUST not be used. */
  AGGREGATION_TEMPORALITY_UNSPECIFIED = 0,
  /**
   * AGGREGATION_TEMPORALITY_DELTA - DELTA is an AggregationTemporality for a metric aggregator which reports
   * changes since last report time. Successive metrics contain aggregation of
   * values from continuous and non-overlapping intervals.
   *
   * The values for a DELTA metric are based only on the time interval
   * associated with one measurement cycle. There is no dependency on
   * previous measurements like is the case for CUMULATIVE metrics.
   *
   * For example, consider a system measuring the number of requests that
   * it receives and reports the sum of these requests every second as a
   * DELTA metric:
   *
   *   1. The system starts receiving at time=t_0.
   *   2. A request is received, the system measures 1 request.
   *   3. A request is received, the system measures 1 request.
   *   4. A request is received, the system measures 1 request.
   *   5. The 1 second collection cycle ends. A metric is exported for the
   *      number of requests received over the interval of time t_0 to
   *      t_0+1 with a value of 3.
   *   6. A request is received, the system measures 1 request.
   *   7. A request is received, the system measures 1 request.
   *   8. The 1 second collection cycle ends. A metric is exported for the
   *      number of requests received over the interval of time t_0+1 to
   *      t_0+2 with a value of 2.
   */
  AGGREGATION_TEMPORALITY_DELTA = 1,
  /**
   * AGGREGATION_TEMPORALITY_CUMULATIVE - CUMULATIVE is an AggregationTemporality for a metric aggregator which
   * reports changes since a fixed start time. This means that current values
   * of a CUMULATIVE metric depend on all previous measurements since the
   * start time. Because of this, the sender is required to retain this state
   * in some form. If this state is lost or invalidated, the CUMULATIVE metric
   * values MUST be reset and a new fixed start time following the last
   * reported measurement time sent MUST be used.
   *
   * For example, consider a system measuring the number of requests that
   * it receives and reports the sum of these requests every second as a
   * CUMULATIVE metric:
   *
   *   1. The system starts receiving at time=t_0.
   *   2. A request is received, the system measures 1 request.
   *   3. A request is received, the system measures 1 request.
   *   4. A request is received, the system measures 1 request.
   *   5. The 1 second collection cycle ends. A metric is exported for the
   *      number of requests received over the interval of time t_0 to
   *      t_0+1 with a value of 3.
   *   6. A request is received, the system measures 1 request.
   *   7. A request is received, the system measures 1 request.
   *   8. The 1 second collection cycle ends. A metric is exported for the
   *      number of requests received over the interval of time t_0 to
   *      t_0+2 with a value of 5.
   *   9. The system experiences a fault and loses state.
   *   10. The system recovers and resumes receiving at time=t_1.
   *   11. A request is received, the system measures 1 request.
   *   12. The 1 second collection cycle ends. A metric is exported for the
   *      number of requests received over the interval of time t_1 to
   *      t_0+1 with a value of 1.
   *
   * Note: Even though, when reporting changes since last report time, using
   * CUMULATIVE is valid, it is not recommended. This may cause problems for
   * systems that do not use start_time to determine when the aggregation
   * value was reset (e.g. Prometheus).
   */
  AGGREGATION_TEMPORALITY_CUMULATIVE = 2,
  UNRECOGNIZED = -1,
}

/**
 * DataPointFlags is defined as a protobuf 'uint32' type and is to be used as a
 * bit-field representing 32 distinct boolean flags.  Each flag defined in this
 * enum is a bit-mask.  To test the presence of a single flag in the flags of
 * a data point, for example, use an expression like:
 *
 *   (point.flags & DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK) == DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK
 */
export enum DataPointFlags {
  /**
   * DATA_POINT_FLAGS_DO_NOT_USE - The zero value for the enum. Should not be used for comparisons.
   * Instead use bitwise "and" with the appropriate mask as shown above.
   */
  DATA_POINT_FLAGS_DO_NOT_USE = 0,
  /**
   * DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK - This DataPoint is valid but has no recorded value.  This value
   * SHOULD be used to reflect explicitly missing data in a series, as
   * for an equivalent to the Prometheus "staleness marker".
   */
  DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK = 1,
  UNRECOGNIZED = -1,
}

/**
 * MetricsData represents the metrics data that can be stored in a persistent
 * storage, OR can be embedded by other protocols that transfer OTLP metrics
 * data but do not implement the OTLP protocol.
 *
 * MetricsData
 * └─── ResourceMetrics
 *   ├── Resource
 *   ├── SchemaURL
 *   └── ScopeMetrics
 *      ├── Scope
 *      ├── SchemaURL
 *      └── Metric
 *         ├── Name
 *         ├── Description
 *         ├── Unit
 *         └── data
 *            ├── Gauge
 *            ├── Sum
 *            ├── Histogram
 *            ├── ExponentialHistogram
 *            └── Summary
 *
 * The main difference between this message and collector protocol is that
 * in this message there will not be any "control" or "metadata" specific to
 * OTLP protocol.
 *
 * When new fields are added into this message, the OTLP request MUST be updated
 * as well.
 */
export interface MetricsData {
  /**
   * An array of ResourceMetrics.
   * For data coming from a single resource this array will typically contain
   * one element. Intermediary nodes that receive data from multiple origins
   * typically batch the data before forwarding further and in that case this
   * array will contain multiple elements.
   */
  resourceMetrics?: ResourceMetrics[] | undefined;
}

/** A collection of ScopeMetrics from a Resource. */
export interface ResourceMetrics {
  /**
   * The resource for the metrics in this message.
   * If this field is not set then no resource info is known.
   */
  resource?: Resource | undefined;
  /** A list of metrics that originate from a resource. */
  scopeMetrics?: ScopeMetrics[] | undefined;
  /**
   * The Schema URL, if known. This is the identifier of the Schema that the resource data
   * is recorded in. Notably, the last part of the URL path is the version number of the
   * schema: http[s]://server[:port]/path/<version>. To learn more about Schema URL see
   * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url
   * This schema_url applies to the data in the "resource" field. It does not apply
   * to the data in the "scope_metrics" field which have their own schema_url field.
   */
  schemaUrl?: string | undefined;
}

/** A collection of Metrics produced by an Scope. */
export interface ScopeMetrics {
  /**
   * The instrumentation scope information for the metrics in this message.
   * Semantically when InstrumentationScope isn't set, it is equivalent with
   * an empty instrumentation scope name (unknown).
   */
  scope?: InstrumentationScope | undefined;
  /** A list of metrics that originate from an instrumentation library. */
  metrics?: Metric[] | undefined;
  /**
   * The Schema URL, if known. This is the identifier of the Schema that the metric data
   * is recorded in. Notably, the last part of the URL path is the version number of the
   * schema: http[s]://server[:port]/path/<version>. To learn more about Schema URL see
   * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url
   * This schema_url applies to the data in the "scope" field and all metrics in the
   * "metrics" field.
   */
  schemaUrl?: string | undefined;
}

/**
 * Defines a Metric which has one or more timeseries.  The following is a
 * brief summary of the Metric data model.  For more details, see:
 *
 *   https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/data-model.md
 *
 * The data model and relation between entities is shown in the
 * diagram below. Here, "DataPoint" is the term used to refer to any
 * one of the specific data point value types, and "points" is the term used
 * to refer to any one of the lists of points contained in the Metric.
 *
 * - Metric is composed of a metadata and data.
 * - Metadata part contains a name, description, unit.
 * - Data is one of the possible types (Sum, Gauge, Histogram, Summary).
 * - DataPoint contains timestamps, attributes, and one of the possible value type
 *   fields.
 *
 *    Metric
 *  +------------+
 *  |name        |
 *  |description |
 *  |unit        |     +------------------------------------+
 *  |data        |---> |Gauge, Sum, Histogram, Summary, ... |
 *  +------------+     +------------------------------------+
 *
 *    Data [One of Gauge, Sum, Histogram, Summary, ...]
 *  +-----------+
 *  |...        |  // Metadata about the Data.
 *  |points     |--+
 *  +-----------+  |
 *                 |      +---------------------------+
 *                 |      |DataPoint 1                |
 *                 v      |+------+------+   +------+ |
 *              +-----+   ||label |label |...|label | |
 *              |  1  |-->||value1|value2|...|valueN| |
 *              +-----+   |+------+------+   +------+ |
 *              |  .  |   |+-----+                    |
 *              |  .  |   ||value|                    |
 *              |  .  |   |+-----+                    |
 *              |  .  |   +---------------------------+
 *              |  .  |                   .
 *              |  .  |                   .
 *              |  .  |                   .
 *              |  .  |   +---------------------------+
 *              |  .  |   |DataPoint M                |
 *              +-----+   |+------+------+   +------+ |
 *              |  M  |-->||label |label |...|label | |
 *              +-----+   ||value1|value2|...|valueN| |
 *                        |+------+------+   +------+ |
 *                        |+-----+                    |
 *                        ||value|                    |
 *                        |+-----+                    |
 *                        +---------------------------+
 *
 * Each distinct type of DataPoint represents the output of a specific
 * aggregation function, the result of applying the DataPoint's
 * associated function of to one or more measurements.
 *
 * All DataPoint types have three common fields:
 * - Attributes includes key-value pairs associated with the data point
 * - TimeUnixNano is required, set to the end time of the aggregation
 * - StartTimeUnixNano is optional, but strongly encouraged for DataPoints
 *   having an AggregationTemporality field, as discussed below.
 *
 * Both TimeUnixNano and StartTimeUnixNano values are expressed as
 * UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
 *
 * # TimeUnixNano
 *
 * This field is required, having consistent interpretation across
 * DataPoint types.  TimeUnixNano is the moment corresponding to when
 * the data point's aggregate value was captured.
 *
 * Data points with the 0 value for TimeUnixNano SHOULD be rejected
 * by consumers.
 *
 * # StartTimeUnixNano
 *
 * StartTimeUnixNano in general allows detecting when a sequence of
 * observations is unbroken.  This field indicates to consumers the
 * start time for points with cumulative and delta
 * AggregationTemporality, and it should be included whenever possible
 * to support correct rate calculation.  Although it may be omitted
 * when the start time is truly unknown, setting StartTimeUnixNano is
 * strongly encouraged.
 */
export interface Metric {
  /** The name of the metric. */
  name?: string | undefined;
  /** A description of the metric, which can be used in documentation. */
  description?: string | undefined;
  /**
   * The unit in which the metric value is reported. Follows the format
   * described by https://unitsofmeasure.org/ucum.html.
   */
  unit?: string | undefined;
  gauge?: Gauge | undefined;
  sum?: Sum | undefined;
  histogram?: Histogram | undefined;
  exponentialHistogram?: ExponentialHistogram | undefined;
  summary?: Summary | undefined;
  /**
   * Additional metadata attributes that describe the metric. [Optional].
   * Attributes are non-identifying.
   * Consumers SHOULD NOT need to be aware of these attributes.
   * These attributes MAY be used to encode information allowing
   * for lossless roundtrip translation to / from another data model.
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   */
  metadata?: KeyValue[] | undefined;
}

/**
 * Gauge represents the type of a scalar metric that always exports the
 * "current value" for every data point. It should be used for an "unknown"
 * aggregation.
 *
 * A Gauge does not support different aggregation temporalities. Given the
 * aggregation is unknown, points cannot be combined using the same
 * aggregation, regardless of aggregation temporalities. Therefore,
 * AggregationTemporality is not included. Consequently, this also means
 * "StartTimeUnixNano" is ignored for all data points.
 */
export interface Gauge {
  /**
   * The time series data points.
   * Note: Multiple time series may be included (same timestamp, different attributes).
   */
  dataPoints?: NumberDataPoint[] | undefined;
}

/**
 * Sum represents the type of a scalar metric that is calculated as a sum of all
 * reported measurements over a time interval.
 */
export interface Sum {
  /**
   * The time series data points.
   * Note: Multiple time series may be included (same timestamp, different attributes).
   */
  dataPoints?: NumberDataPoint[] | undefined;
  /**
   * aggregation_temporality describes if the aggregator reports delta changes
   * since last report time, or cumulative changes since a fixed start time.
   */
  aggregationTemporality?: AggregationTemporality | undefined;
  /** Represents whether the sum is monotonic. */
  isMonotonic?: boolean | undefined;
}

/**
 * Histogram represents the type of a metric that is calculated by aggregating
 * as a Histogram of all reported measurements over a time interval.
 */
export interface Histogram {
  /**
   * The time series data points.
   * Note: Multiple time series may be included (same timestamp, different attributes).
   */
  dataPoints?: HistogramDataPoint[] | undefined;
  /**
   * aggregation_temporality describes if the aggregator reports delta changes
   * since last report time, or cumulative changes since a fixed start time.
   */
  aggregationTemporality?: AggregationTemporality | undefined;
}

/**
 * ExponentialHistogram represents the type of a metric that is calculated by aggregating
 * as a ExponentialHistogram of all reported double measurements over a time interval.
 */
export interface ExponentialHistogram {
  /**
   * The time series data points.
   * Note: Multiple time series may be included (same timestamp, different attributes).
   */
  dataPoints?: ExponentialHistogramDataPoint[] | undefined;
  /**
   * aggregation_temporality describes if the aggregator reports delta changes
   * since last report time, or cumulative changes since a fixed start time.
   */
  aggregationTemporality?: AggregationTemporality | undefined;
}

/**
 * Summary metric data are used to convey quantile summaries,
 * a Prometheus (see: https://prometheus.io/docs/concepts/metric_types/#summary)
 * and OpenMetrics (see: https://github.com/prometheus/OpenMetrics/blob/4dbf6075567ab43296eed941037c12951faafb92/protos/prometheus.proto#L45)
 * data type. These data points cannot always be merged in a meaningful way.
 * While they can be useful in some applications, histogram data points are
 * recommended for new applications.
 * Summary metrics do not have an aggregation temporality field. This is
 * because the count and sum fields of a SummaryDataPoint are assumed to be
 * cumulative values.
 */
export interface Summary {
  /**
   * The time series data points.
   * Note: Multiple time series may be included (same timestamp, different attributes).
   */
  dataPoints?: SummaryDataPoint[] | undefined;
}

/**
 * NumberDataPoint is a single data point in a timeseries that describes the
 * time-varying scalar value of a metric.
 */
export interface NumberDataPoint {
  /**
   * The set of key/value pairs that uniquely identify the timeseries from
   * where this point belongs. The list may be empty (may contain 0 elements).
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   */
  attributes?: KeyValue[] | undefined;
  /**
   * StartTimeUnixNano is optional but strongly encouraged, see the
   * the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   */
  startTimeUnixNano?: string | undefined;
  /**
   * TimeUnixNano is required, see the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   */
  timeUnixNano?: string | undefined;
  asDouble?: number | undefined;
  asInt?: string | undefined;
  /**
   * (Optional) List of exemplars collected from
   * measurements that were used to form the data point
   */
  exemplars?: Exemplar[] | undefined;
  /**
   * Flags that apply to this specific data point.  See DataPointFlags
   * for the available flags and their meaning.
   */
  flags?: number | undefined;
}

/**
 * HistogramDataPoint is a single data point in a timeseries that describes the
 * time-varying values of a Histogram. A Histogram contains summary statistics
 * for a population of values, it may optionally contain the distribution of
 * those values across a set of buckets.
 *
 * If the histogram contains the distribution of values, then both
 * "explicit_bounds" and "bucket counts" fields must be defined.
 * If the histogram does not contain the distribution of values, then both
 * "explicit_bounds" and "bucket_counts" must be omitted and only "count" and
 * "sum" are known.
 */
export interface HistogramDataPoint {
  /**
   * The set of key/value pairs that uniquely identify the timeseries from
   * where this point belongs. The list may be empty (may contain 0 elements).
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   */
  attributes?: KeyValue[] | undefined;
  /**
   * StartTimeUnixNano is optional but strongly encouraged, see the
   * the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   */
  startTimeUnixNano?: string | undefined;
  /**
   * TimeUnixNano is required, see the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   */
  timeUnixNano?: string | undefined;
  /**
   * count is the number of values in the population. Must be non-negative. This
   * value must be equal to the sum of the "count" fields in buckets if a
   * histogram is provided.
   */
  count?: string | number | undefined;
  /**
   * sum of the values in the population. If count is zero then this field
   * must be zero.
   *
   * Note: Sum should only be filled out when measuring non-negative discrete
   * events, and is assumed to be monotonic over the values of these events.
   * Negative events *can* be recorded, but sum should not be filled out when
   * doing so.  This is specifically to enforce compatibility w/ OpenMetrics,
   * see: https://github.com/prometheus/OpenMetrics/blob/v1.0.0/specification/OpenMetrics.md#histogram
   */
  sum?: number | undefined;
  /**
   * bucket_counts is an optional field contains the count values of histogram
   * for each bucket.
   *
   * The sum of the bucket_counts must equal the value in the count field.
   *
   * The number of elements in bucket_counts array must be by one greater than
   * the number of elements in explicit_bounds array. The exception to this rule
   * is when the length of bucket_counts is 0, then the length of explicit_bounds
   * must also be 0.
   */
  bucketCounts?: number[] | undefined;
  /**
   * explicit_bounds specifies buckets with explicitly defined bounds for values.
   *
   * The boundaries for bucket at index i are:
   *
   * (-infinity, explicit_bounds[i]] for i == 0
   * (explicit_bounds[i-1], explicit_bounds[i]] for 0 < i < size(explicit_bounds)
   * (explicit_bounds[i-1], +infinity) for i == size(explicit_bounds)
   *
   * The values in the explicit_bounds array must be strictly increasing.
   *
   * Histogram buckets are inclusive of their upper boundary, except the last
   * bucket where the boundary is at infinity. This format is intentionally
   * compatible with the OpenMetrics histogram definition.
   *
   * If bucket_counts length is 0 then explicit_bounds length must also be 0,
   * otherwise the data point is invalid.
   */
  explicitBounds?: number[] | undefined;
  /**
   * (Optional) List of exemplars collected from
   * measurements that were used to form the data point
   */
  exemplars?: Exemplar[] | undefined;
  /**
   * Flags that apply to this specific data point.  See DataPointFlags
   * for the available flags and their meaning.
   */
  flags?: number | undefined;
  /** min is the minimum value over (start_time, end_time]. */
  min?: number | undefined;
  /** max is the maximum value over (start_time, end_time]. */
  max?: number | undefined;
}

/**
 * ExponentialHistogramDataPoint is a single data point in a timeseries that describes the
 * time-varying values of a ExponentialHistogram of double values. A ExponentialHistogram contains
 * summary statistics for a population of values, it may optionally contain the
 * distribution of those values across a set of buckets.
 */
export interface ExponentialHistogramDataPoint {
  /**
   * The set of key/value pairs that uniquely identify the timeseries from
   * where this point belongs. The list may be empty (may contain 0 elements).
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   */
  attributes?: KeyValue[] | undefined;
  /**
   * StartTimeUnixNano is optional but strongly encouraged, see the
   * the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   */
  startTimeUnixNano?: string | undefined;
  /**
   * TimeUnixNano is required, see the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   */
  timeUnixNano?: string | undefined;
  /**
   * The number of values in the population. Must be
   * non-negative. This value must be equal to the sum of the "bucket_counts"
   * values in the positive and negative Buckets plus the "zero_count" field.
   */
  count?: string | number | undefined;
  /**
   * The sum of the values in the population. If count is zero then this field
   * must be zero.
   *
   * Note: Sum should only be filled out when measuring non-negative discrete
   * events, and is assumed to be monotonic over the values of these events.
   * Negative events *can* be recorded, but sum should not be filled out when
   * doing so.  This is specifically to enforce compatibility w/ OpenMetrics,
   * see: https://github.com/prometheus/OpenMetrics/blob/v1.0.0/specification/OpenMetrics.md#histogram
   */
  sum?: number | undefined;
  /**
   * scale describes the resolution of the histogram.  Boundaries are
   * located at powers of the base, where:
   *
   *   base = (2^(2^-scale))
   *
   * The histogram bucket identified by `index`, a signed integer,
   * contains values that are greater than (base^index) and
   * less than or equal to (base^(index+1)).
   *
   * The positive and negative ranges of the histogram are expressed
   * separately.  Negative values are mapped by their absolute value
   * into the negative range using the same scale as the positive range.
   *
   * scale is not restricted by the protocol, as the permissible
   * values depend on the range of the data.
   */
  scale?: number | undefined;
  /**
   * The count of values that are either exactly zero or
   * within the region considered zero by the instrumentation at the
   * tolerated degree of precision.  This bucket stores values that
   * cannot be expressed using the standard exponential formula as
   * well as values that have been rounded to zero.
   *
   * Implementations MAY consider the zero bucket to have probability
   * mass equal to (zero_count / count).
   */
  zeroCount?: number | undefined;
  /** positive carries the positive range of exponential bucket counts. */
  positive?: ExponentialHistogramDataPoint_Buckets | undefined;
  /** negative carries the negative range of exponential bucket counts. */
  negative?: ExponentialHistogramDataPoint_Buckets | undefined;
  /**
   * Flags that apply to this specific data point.  See DataPointFlags
   * for the available flags and their meaning.
   */
  flags?: number | undefined;
  /**
   * (Optional) List of exemplars collected from
   * measurements that were used to form the data point
   */
  exemplars?: Exemplar[] | undefined;
  /** The minimum value over (start_time, end_time]. */
  min?: number | undefined;
  /** The maximum value over (start_time, end_time]. */
  max?: number | undefined;
  /**
   * ZeroThreshold may be optionally set to convey the width of the zero
   * region. Where the zero region is defined as the closed interval
   * [-ZeroThreshold, ZeroThreshold].
   * When ZeroThreshold is 0, zero count bucket stores values that cannot be
   * expressed using the standard exponential formula as well as values that
   * have been rounded to zero.
   */
  zeroThreshold?: number | undefined;
}

/**
 * Buckets are a set of bucket counts, encoded in a contiguous array
 * of counts.
 */
export interface ExponentialHistogramDataPoint_Buckets {
  /**
   * The bucket index of the first entry in the bucket_counts array.
   *
   * Note: This uses a varint encoding as a simple form of compression.
   */
  offset?: number | undefined;
  /**
   * An array of count values, where bucket_counts[i] carries
   * the count of the bucket at index (offset+i). bucket_counts[i] is the count
   * of values greater than base^(offset+i) and less than or equal to
   * base^(offset+i+1).
   *
   * Note: By contrast, the explicit HistogramDataPoint uses
   * fixed64.  This field is expected to have many buckets,
   * especially zeros, so uint64 has been selected to ensure
   * varint encoding.
   */
  bucketCounts?: (string | number)[] | undefined;
}

/**
 * SummaryDataPoint is a single data point in a timeseries that describes the
 * time-varying values of a Summary metric. The count and sum fields represent
 * cumulative values.
 */
export interface SummaryDataPoint {
  /**
   * The set of key/value pairs that uniquely identify the timeseries from
   * where this point belongs. The list may be empty (may contain 0 elements).
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   */
  attributes?: KeyValue[] | undefined;
  /**
   * StartTimeUnixNano is optional but strongly encouraged, see the
   * the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   */
  startTimeUnixNano?: string | undefined;
  /**
   * TimeUnixNano is required, see the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   */
  timeUnixNano?: string | undefined;
  /** count is the number of values in the population. Must be non-negative. */
  count?: string | number | undefined;
  /**
   * sum of the values in the population. If count is zero then this field
   * must be zero.
   *
   * Note: Sum should only be filled out when measuring non-negative discrete
   * events, and is assumed to be monotonic over the values of these events.
   * Negative events *can* be recorded, but sum should not be filled out when
   * doing so.  This is specifically to enforce compatibility w/ OpenMetrics,
   * see: https://github.com/prometheus/OpenMetrics/blob/v1.0.0/specification/OpenMetrics.md#summary
   */
  sum?: number | undefined;
  /**
   * (Optional) list of values at different quantiles of the distribution calculated
   * from the current snapshot. The quantiles must be strictly increasing.
   */
  quantileValues?: SummaryDataPoint_ValueAtQuantile[] | undefined;
  /**
   * Flags that apply to this specific data point.  See DataPointFlags
   * for the available flags and their meaning.
   */
  flags?: number | undefined;
}

/**
 * Represents the value at a given quantile of a distribution.
 *
 * To record Min and Max values following conventions are used:
 * - The 1.0 quantile is equivalent to the maximum value observed.
 * - The 0.0 quantile is equivalent to the minimum value observed.
 *
 * See the following issue for more context:
 * https://github.com/open-telemetry/opentelemetry-proto/issues/125
 */
export interface SummaryDataPoint_ValueAtQuantile {
  /**
   * The quantile of a distribution. Must be in the interval
   * [0.0, 1.0].
   */
  quantile?: number | undefined;
  /**
   * The value at the given quantile of a distribution.
   *
   * Quantile values must NOT be negative.
   */
  value?: number | undefined;
}

/**
 * A representation of an exemplar, which is a sample input measurement.
 * Exemplars also hold information about the environment when the measurement
 * was recorded, for example the span and trace ID of the active span when the
 * exemplar was recorded.
 */
export interface Exemplar {
  /**
   * The set of key/value pairs that were filtered out by the aggregator, but
   * recorded alongside the original measurement. Only key/value pairs that were
   * filtered out by the aggregator should be included
   */
  filteredAttributes?: KeyValue[] | undefined;
  /**
   * time_unix_nano is the exact time when this exemplar was recorded
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   */
  timeUnixNano?: string | undefined;
  asDouble?: number | undefined;
  asInt?: string | undefined;
  /**
   * (Optional) Span ID of the exemplar trace.
   * span_id may be missing if the measurement is not recorded inside a trace
   * or if the trace is not sampled.
   */
  spanId?: string | undefined;
  /**
   * (Optional) Trace ID of the exemplar trace.
   * trace_id may be missing if the measurement is not recorded inside a trace
   * or if the trace is not sampled.
   */
  traceId?: Uint8Array | undefined;
}
